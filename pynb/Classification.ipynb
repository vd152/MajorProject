{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Garvit-k/flower-classifier/blob/master/Flower_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "iRo90eIXHF58"
      },
      "outputs": [],
      "source": [
        "#import nessarary libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import load_model\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import pandas\n",
        "import os\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import tensorflowjs as tfjs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "W7W9O4OLHHG7",
        "outputId": "1e9fffb4-a4ab-41b5-881d-09ec1ba2dea6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['daisy', 'dandelion', 'rose', 'sunflower', 'tulip']\n"
          ]
        }
      ],
      "source": [
        "path = 'C:\\\\Users\\\\Vidhi\\\\Desktop\\\\major project\\\\Application\\\\data\\\\uploads'\n",
        "#path = 'C:\\\\Users\\\\Vidhi\\\\Desktop\\\\major project\\\\Flower_Classification_Tensorflow.js\\\\train\\\\data\\\\train'\n",
        "folders = os.listdir(path)\n",
        "print(folders)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "lhohDqo7H4DY"
      },
      "outputs": [],
      "source": [
        "image_names =[]\n",
        "train_lables =[]\n",
        "train_images =[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        },
        "colab_type": "code",
        "id": "OS3_Y3bVIgx5",
        "outputId": "4bdcd97f-d771-4c07-f02a-2996956973ca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "daisy\n",
            "dandelion\n",
            "rose\n",
            "sunflower\n",
            "tulip\n",
            "53047296\n"
          ]
        }
      ],
      "source": [
        "# resizing and enumrating lists and transform it into numpy array\n",
        "\n",
        "size = 64,64\n",
        "\n",
        "for folder in folders:\n",
        "  print(folder)\n",
        "  for file in os.listdir(os.path.join(path,folder)):\n",
        "    if file.endswith('jpg') or file.endswith('png'):\n",
        "      image_names.append(os.path.join(path,folder,file))\n",
        "      train_lables.append(folder)\n",
        "      img = cv2.imread(os.path.join(path,folder,file))\n",
        "      img = cv2.resize(img,size)\n",
        "      train_images.append(img)\n",
        "    else:\n",
        "      continue\n",
        "      \n",
        "train = np.array(train_images)\n",
        "print(train.size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "wWTopktvLP_0"
      },
      "outputs": [],
      "source": [
        "train = train.astype('float32') / 255.0\n",
        "\n",
        "# extract lables\n",
        "label_dummies = pandas.get_dummies(train_lables)\n",
        "labels =  label_dummies.values.argmax(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "colab_type": "code",
        "id": "umiIcrexQItK",
        "outputId": "5409f318-230f-46da-e177-a333573459d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['daisy' 'dandelion' 'rose' 'sunflower' 'tulip']\n",
            "[0 1 2 3 4]\n"
          ]
        }
      ],
      "source": [
        "print(pandas.unique(train_lables))\n",
        "print(pandas.unique(labels))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "Oqqq9lOUQXlI"
      },
      "outputs": [],
      "source": [
        "# Shuffle the labels and images randomly for better results\n",
        "\n",
        "union_list = list(zip(train, labels))\n",
        "random.shuffle(union_list)\n",
        "train,labels = zip(*union_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "z357QmP8XLiH"
      },
      "outputs": [],
      "source": [
        "# Convert the shuffled list to numpy array type\n",
        "train = np.array(train)\n",
        "labels = np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        },
        "colab_type": "code",
        "id": "whpxJXvAXPsL",
        "outputId": "508b2747-4d57-410c-ab67-c86decbcb141"
      },
      "outputs": [],
      "source": [
        "# Building a model\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Flatten(input_shape = (64,64,3)),\n",
        "    keras.layers.Dense(128,activation = tf.nn.tanh),\n",
        "    keras.layers.Dense(32,activation = tf.nn.softmax)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {},
        "colab_type": "code",
        "id": "PTfX4sgkYYPP"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Vidhi\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\keras\\optimizer_v2\\adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# model parameters\n",
        "model.compile(optimizer = keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False),\n",
        "              loss = 'sparse_categorical_crossentropy',\n",
        "              metrics = ['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2990
        },
        "colab_type": "code",
        "id": "oAqOLgB-ZCxb",
        "outputId": "b3a51bcb-0834-4596-86e4-8d113803d197"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/80\n",
            "135/135 [==============================] - 2s 12ms/step - loss: 1.6690 - accuracy: 0.2673\n",
            "Epoch 2/80\n",
            "135/135 [==============================] - 2s 12ms/step - loss: 1.5173 - accuracy: 0.3180\n",
            "Epoch 3/80\n",
            "135/135 [==============================] - 2s 12ms/step - loss: 1.5074 - accuracy: 0.3178\n",
            "Epoch 4/80\n",
            "135/135 [==============================] - 2s 12ms/step - loss: 1.4696 - accuracy: 0.3653\n",
            "Epoch 5/80\n",
            "135/135 [==============================] - 2s 12ms/step - loss: 1.4439 - accuracy: 0.3875\n",
            "Epoch 6/80\n",
            "135/135 [==============================] - 2s 12ms/step - loss: 1.4000 - accuracy: 0.4007\n",
            "Epoch 7/80\n",
            "135/135 [==============================] - 2s 12ms/step - loss: 1.3761 - accuracy: 0.4070\n",
            "Epoch 8/80\n",
            "135/135 [==============================] - 2s 12ms/step - loss: 1.3565 - accuracy: 0.4093\n",
            "Epoch 9/80\n",
            "135/135 [==============================] - 2s 12ms/step - loss: 1.3409 - accuracy: 0.4302\n",
            "Epoch 10/80\n",
            "135/135 [==============================] - 2s 12ms/step - loss: 1.3240 - accuracy: 0.4292\n",
            "Epoch 11/80\n",
            "135/135 [==============================] - 2s 12ms/step - loss: 1.3324 - accuracy: 0.4302\n",
            "Epoch 12/80\n",
            "135/135 [==============================] - 2s 12ms/step - loss: 1.3526 - accuracy: 0.4211\n",
            "Epoch 13/80\n",
            "135/135 [==============================] - 2s 12ms/step - loss: 1.3495 - accuracy: 0.4026\n",
            "Epoch 14/80\n",
            "135/135 [==============================] - 2s 12ms/step - loss: 1.3014 - accuracy: 0.4334\n",
            "Epoch 15/80\n",
            "135/135 [==============================] - 2s 12ms/step - loss: 1.2871 - accuracy: 0.4626\n",
            "Epoch 16/80\n",
            "135/135 [==============================] - 2s 12ms/step - loss: 1.2905 - accuracy: 0.4526\n",
            "Epoch 17/80\n",
            "135/135 [==============================] - 2s 11ms/step - loss: 1.2970 - accuracy: 0.4364\n",
            "Epoch 18/80\n",
            "135/135 [==============================] - 2s 11ms/step - loss: 1.2762 - accuracy: 0.4626\n",
            "Epoch 19/80\n",
            "135/135 [==============================] - 2s 12ms/step - loss: 1.2689 - accuracy: 0.4549\n",
            "Epoch 20/80\n",
            "135/135 [==============================] - 2s 11ms/step - loss: 1.2987 - accuracy: 0.4431\n",
            "Epoch 21/80\n",
            "135/135 [==============================] - 2s 12ms/step - loss: 1.2869 - accuracy: 0.4306\n",
            "Epoch 22/80\n",
            "135/135 [==============================] - 2s 12ms/step - loss: 1.3222 - accuracy: 0.4170\n",
            "Epoch 23/80\n",
            "135/135 [==============================] - 2s 12ms/step - loss: 1.2946 - accuracy: 0.4239\n",
            "Epoch 24/80\n",
            "135/135 [==============================] - 2s 11ms/step - loss: 1.2814 - accuracy: 0.4464\n",
            "Epoch 25/80\n",
            "135/135 [==============================] - 2s 11ms/step - loss: 1.2664 - accuracy: 0.4596\n",
            "Epoch 26/80\n",
            "135/135 [==============================] - 2s 12ms/step - loss: 1.2794 - accuracy: 0.4422\n",
            "Epoch 27/80\n",
            "135/135 [==============================] - 2s 12ms/step - loss: 1.2713 - accuracy: 0.4505\n",
            "Epoch 28/80\n",
            "135/135 [==============================] - 2s 12ms/step - loss: 1.2329 - accuracy: 0.4707\n",
            "Epoch 29/80\n",
            "135/135 [==============================] - 2s 12ms/step - loss: 1.2491 - accuracy: 0.4672\n",
            "Epoch 30/80\n",
            "135/135 [==============================] - 2s 11ms/step - loss: 1.2258 - accuracy: 0.4781\n",
            "Epoch 31/80\n",
            "135/135 [==============================] - 2s 11ms/step - loss: 1.2312 - accuracy: 0.4693\n",
            "Epoch 32/80\n",
            "135/135 [==============================] - 2s 12ms/step - loss: 1.2333 - accuracy: 0.4705\n",
            "Epoch 33/80\n",
            "135/135 [==============================] - 2s 12ms/step - loss: 1.2264 - accuracy: 0.4841\n",
            "Epoch 34/80\n",
            "135/135 [==============================] - 2s 11ms/step - loss: 1.2366 - accuracy: 0.4640\n",
            "Epoch 35/80\n",
            "135/135 [==============================] - 2s 12ms/step - loss: 1.2215 - accuracy: 0.4885\n",
            "Epoch 36/80\n",
            "135/135 [==============================] - 2s 12ms/step - loss: 1.2071 - accuracy: 0.4832\n",
            "Epoch 37/80\n",
            "135/135 [==============================] - 2s 12ms/step - loss: 1.1896 - accuracy: 0.4915\n",
            "Epoch 38/80\n",
            "135/135 [==============================] - 2s 12ms/step - loss: 1.2631 - accuracy: 0.4457\n",
            "Epoch 39/80\n",
            "135/135 [==============================] - 2s 12ms/step - loss: 1.3253 - accuracy: 0.4033\n",
            "Epoch 40/80\n",
            "135/135 [==============================] - 2s 11ms/step - loss: 1.2951 - accuracy: 0.4288\n",
            "Epoch 41/80\n",
            "135/135 [==============================] - 2s 12ms/step - loss: 1.2615 - accuracy: 0.4441\n",
            "Epoch 42/80\n",
            "135/135 [==============================] - 2s 14ms/step - loss: 1.2271 - accuracy: 0.4612\n",
            "Epoch 43/80\n",
            "135/135 [==============================] - 2s 12ms/step - loss: 1.2697 - accuracy: 0.4401\n",
            "Epoch 44/80\n",
            "135/135 [==============================] - 1s 10ms/step - loss: 1.3236 - accuracy: 0.4126\n",
            "Epoch 45/80\n",
            "135/135 [==============================] - 1s 11ms/step - loss: 1.2346 - accuracy: 0.4677\n",
            "Epoch 46/80\n",
            "135/135 [==============================] - 1s 10ms/step - loss: 1.2072 - accuracy: 0.4797\n",
            "Epoch 47/80\n",
            "135/135 [==============================] - 1s 10ms/step - loss: 1.2014 - accuracy: 0.4732\n",
            "Epoch 48/80\n",
            "135/135 [==============================] - 2s 11ms/step - loss: 1.2499 - accuracy: 0.4306\n",
            "Epoch 49/80\n",
            "135/135 [==============================] - 1s 10ms/step - loss: 1.2377 - accuracy: 0.4443\n",
            "Epoch 50/80\n",
            "135/135 [==============================] - 1s 10ms/step - loss: 1.1602 - accuracy: 0.4976\n",
            "Epoch 51/80\n",
            "135/135 [==============================] - 1s 10ms/step - loss: 1.1879 - accuracy: 0.4841\n",
            "Epoch 52/80\n",
            "135/135 [==============================] - 1s 10ms/step - loss: 1.1285 - accuracy: 0.5110\n",
            "Epoch 53/80\n",
            "135/135 [==============================] - 1s 10ms/step - loss: 1.1690 - accuracy: 0.4976\n",
            "Epoch 54/80\n",
            "135/135 [==============================] - 2s 11ms/step - loss: 1.1476 - accuracy: 0.5041\n",
            "Epoch 55/80\n",
            "135/135 [==============================] - 2s 14ms/step - loss: 1.1405 - accuracy: 0.5200\n",
            "Epoch 56/80\n",
            "135/135 [==============================] - 1s 11ms/step - loss: 1.1677 - accuracy: 0.4939\n",
            "Epoch 57/80\n",
            "135/135 [==============================] - 2s 12ms/step - loss: 1.1259 - accuracy: 0.5124\n",
            "Epoch 58/80\n",
            "135/135 [==============================] - 1s 11ms/step - loss: 1.1461 - accuracy: 0.5034\n",
            "Epoch 59/80\n",
            "135/135 [==============================] - 2s 14ms/step - loss: 1.1493 - accuracy: 0.5064\n",
            "Epoch 60/80\n",
            "135/135 [==============================] - 1s 11ms/step - loss: 1.1195 - accuracy: 0.5237\n",
            "Epoch 61/80\n",
            "135/135 [==============================] - 2s 16ms/step - loss: 1.1496 - accuracy: 0.5166\n",
            "Epoch 62/80\n",
            "135/135 [==============================] - 1s 11ms/step - loss: 1.2199 - accuracy: 0.5078\n",
            "Epoch 63/80\n",
            "135/135 [==============================] - 2s 17ms/step - loss: 1.2053 - accuracy: 0.5052\n",
            "Epoch 64/80\n",
            "135/135 [==============================] - 2s 13ms/step - loss: 1.1846 - accuracy: 0.5103\n",
            "Epoch 65/80\n",
            "135/135 [==============================] - 2s 12ms/step - loss: 1.1429 - accuracy: 0.5133\n",
            "Epoch 66/80\n",
            "135/135 [==============================] - 2s 12ms/step - loss: 1.1538 - accuracy: 0.5117\n",
            "Epoch 67/80\n",
            "135/135 [==============================] - 2s 12ms/step - loss: 1.0910 - accuracy: 0.5342\n",
            "Epoch 68/80\n",
            "135/135 [==============================] - 2s 11ms/step - loss: 1.1640 - accuracy: 0.5094\n",
            "Epoch 69/80\n",
            "135/135 [==============================] - 2s 12ms/step - loss: 1.0939 - accuracy: 0.5395\n",
            "Epoch 70/80\n",
            "135/135 [==============================] - 2s 12ms/step - loss: 1.0969 - accuracy: 0.5219\n",
            "Epoch 71/80\n",
            "135/135 [==============================] - 2s 12ms/step - loss: 1.1158 - accuracy: 0.5230\n",
            "Epoch 72/80\n",
            "135/135 [==============================] - 2s 12ms/step - loss: 1.1011 - accuracy: 0.5279\n",
            "Epoch 73/80\n",
            "135/135 [==============================] - 2s 12ms/step - loss: 1.0851 - accuracy: 0.5451\n",
            "Epoch 74/80\n",
            "135/135 [==============================] - 2s 12ms/step - loss: 1.0726 - accuracy: 0.5564\n",
            "Epoch 75/80\n",
            "135/135 [==============================] - 2s 12ms/step - loss: 1.0992 - accuracy: 0.5411\n",
            "Epoch 76/80\n",
            "135/135 [==============================] - 2s 12ms/step - loss: 1.1204 - accuracy: 0.5323\n",
            "Epoch 77/80\n",
            "135/135 [==============================] - 2s 13ms/step - loss: 1.1117 - accuracy: 0.5272\n",
            "Epoch 78/80\n",
            "135/135 [==============================] - 2s 13ms/step - loss: 1.0683 - accuracy: 0.5404\n",
            "Epoch 79/80\n",
            "135/135 [==============================] - 2s 13ms/step - loss: 1.0960 - accuracy: 0.5367\n",
            "Epoch 80/80\n",
            "135/135 [==============================] - 2s 14ms/step - loss: 1.0583 - accuracy: 0.5425\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x1a42c2d4be0>"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.fit(train,labels,epochs = 80)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "colab_type": "code",
        "id": "HaQhBfRhZK80",
        "outputId": "f1c2e8e6-616b-40e1-8ce0-2dce209e42c2"
      },
      "outputs": [],
      "source": [
        "# Saving model\n",
        "\n",
        "model.save('mymodel.h5')\n",
        "tfjs.converters.save_keras_model(model, \"tfjsmodel\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tulip\n"
          ]
        }
      ],
      "source": [
        "model2 = keras.models.load_model('./mymodel.h5')\n",
        "p = 'C:\\\\Users\\\\Vidhi\\\\Desktop\\\\major project\\\\Application\\\\data\\\\uploads2\\\\bicycle\\\\bicycle-1650821231928.png'\n",
        "finalimgs = []\n",
        "size = 64,64\n",
        "\n",
        "imgf = cv2.imread(p)\n",
        "imgf = cv2.resize(imgf,size)\n",
        "\n",
        "finalimgs.append(imgf)\n",
        "trainp = np.array(finalimgs)\n",
        "\n",
        "trainp = trainp.astype('float32') / 255.0\n",
        "\n",
        "pred = model2.predict(trainp)\n",
        "cla=np.argmax(pred,axis=1)\n",
        "print(pandas.unique(train_lables)[cla[0]])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "Flower Classification.ipynb",
      "provenance": [],
      "version": "0.3.2"
    },
    "interpreter": {
      "hash": "6a702454195edae8c5d45d3b9db0008165157592e031e3aea62e2374bc2e2b48"
    },
    "kernelspec": {
      "display_name": "Python 3.8.3 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
